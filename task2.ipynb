{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of generate_kernels.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markkod/pc3-enzymes/blob/main/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VxEwG3kUGD08",
        "outputId": "b371c34e-8f6e-426c-cf3d-fc6b5a8858d6"
      },
      "source": [
        "#preinstalled version of pytorch has to be the same as the pre-compiled versions of the pytorch-geometric packages that we download later on.\r\n",
        "#versions might change quickly, so if you get a strange error later on, check the torch version of Google colab later on as follows:\r\n",
        "\r\n",
        "import torch\r\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-VN1RcQBUvc",
        "outputId": "661d2d4b-c529-41e8-ede4-ce5e458edb47"
      },
      "source": [
        "# Script to generate variations of the kernels yourself\n",
        "# https://ucloud.univie.ac.at/index.php/s/E3YKph0jkpbw8TN\n",
        "\n",
        "\n",
        "# #Download the TUDataset Repository with\n",
        "!git clone https://github.com/chrsmrrs/tudataset.git\n",
        "# #move this script to tudataset/tud_benchmark\n",
        "\n",
        "# #Install pytorch geometric: https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "# #Here is the gpu cuda installation, for the cpu version replace cu102 with cpu\n",
        "%pip --no-cache-dir install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-geometric\n",
        "\n",
        "%pip --no-cache-dir install pybind11\n",
        "!sudo apt-get install libeigen3-dev\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tudataset'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (366/366), done.\u001b[K\n",
            "remote: Total 3344 (delta 244), reused 300 (delta 114), pack-reused 2859\u001b[K\n",
            "Receiving objects: 100% (3344/3344), 8.47 MiB | 33.88 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 41.5MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 35.8MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.8)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (51.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp36-none-any.whl size=322720 sha256=d2210e9e9922f7d00f98a20174d46c1f03004d58a25fc21cc72ef86f95310792\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-py4kwm_m/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n",
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/84/fc9dc13ee536ba5e6b8fd10ce368fea5b738fe394c3b296cde7c9b144a92/pybind11-2.6.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 16.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.6.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,294 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 145480 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXKQ-3OcCzMK",
        "outputId": "47b85e33-8aca-4601-d732-94b1fdc31240"
      },
      "source": [
        "%cd ..\n",
        "%cd /content/tudataset/tud_benchmark/kernel_baselines/\n",
        "! ls\n",
        "! g++ -I /usr/include/eigen3 -O3 -shared -std=c++11 -fPIC `python3 -m pybind11 --includes`  kernel_baselines.cpp src/*cpp -o ../kernel_baselines`python3-config --extension-suffix`\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/content/tudataset/tud_benchmark/kernel_baselines\n",
            "kernel_baselines.cpp  src\n",
            "/content/tudataset/tud_benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjESzy3qMo8C",
        "outputId": "e7aef762-8b81-4000-c8da-d616b04f287d"
      },
      "source": [
        "!ls -al /usr/local/cuda"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lrwxrwxrwx 1 root root 9 Dec 21 17:24 /usr/local/cuda -> cuda-10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HOSZDPBbNV"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import kernel_baselines as kb\n",
        "import auxiliarymethods\n",
        "from auxiliarymethods import datasets as dp\n",
        "from scipy.sparse import save_npz\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pq17mvdBdym"
      },
      "source": [
        "def setup_directory(dir_name, verbose=False):\n",
        "    \"\"\"\n",
        "    Setup directory in case it does not exist\n",
        "    Parameters:\n",
        "    -------------\n",
        "    dir_name: str, path + name to directory\n",
        "    verbose: bool, indicates whether directory creation should be printed or not.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        try:\n",
        "            os.makedirs(dir_name)\n",
        "            if verbose:\n",
        "                print(\"Created Directory: {}\".format(dir_name))\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\n",
        "                \"Could not create directory: {}\\n {}\".format(dir_name, e))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWVqxq5B8RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1eaacc1-71be-40cc-c2a2-e970142add89"
      },
      "source": [
        "use_edge_labels = False\n",
        "for USE_LABELS in [True, False]:# Except IMDB-BINARY\n",
        "    for dataset, use_labels in [[\"ENZYMES\", USE_LABELS]]:\n",
        "        if use_labels:\n",
        "            base_path = os.path.join(\"kernels\",\"node_labels\")\n",
        "        else:\n",
        "            base_path = os.path.join(\"kernels\",\"without_labels\")\n",
        "        setup_directory(base_path)\n",
        "        print(\"Start processing data set \", dataset)\n",
        "        # Download dataset.\n",
        "        classes = dp.get_dataset(dataset)\n",
        "        # *Weisfeihler-Lehman*\n",
        "        print(\"Start computing Weisfeihler-Lehman gram matrix and vector representations\")\n",
        "        iterations = 6\n",
        "        #0 taking just the nodelabels themselves into account; \n",
        "        #1 considers nearest-neighbours, 2 one layer deeper and so on\n",
        "        for i in range(1, iterations):\n",
        "            print(\"Start iteration \", i)\n",
        "            #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
        "            gram_matrix_wl = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\n",
        "            np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{i}.csv\"),\n",
        "                    gram_matrix_wl,\n",
        "                    delimiter=\";\")\n",
        "            #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\n",
        "            vectors_wl = kb.compute_wl_1_sparse(dataset, i, use_labels, use_edge_labels)\n",
        "            save_npz(os.path.join(base_path,f\"{dataset}_vectors_wl{i}.npz\"),\n",
        "                    vectors_wl, compressed=True)\n",
        "\n",
        "        # *Graphlet kernel*\n",
        "        print(\"Start computing Graphlet gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Graphlet kernel\n",
        "        gram_matrix_graphlet= kb.compute_graphlet_dense(dataset, use_labels, use_edge_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_graphlet.csv\"),\n",
        "                gram_matrix_graphlet,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Graphlet vector representation\")\n",
        "        #Sparse Vectors for the Graphlet kernel\n",
        "        vectors_graphlet = kb.compute_graphlet_sparse(dataset, use_labels, use_edge_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_graphlet.npz\"),\n",
        "                vectors_graphlet, compressed=True)\n",
        "\n",
        "\n",
        "        print(\"Start computing Shortest path gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Shortest path kernel\n",
        "        gram_matrix_shortestpath = kb.compute_shortestpath_dense(dataset, use_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_shortestpath.csv\"),\n",
        "                gram_matrix_shortestpath,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Shortest path vector representation\")\n",
        "\n",
        "        #Sparse Vectors for the Shortest path kernel\n",
        "        vectors_shortestpath = kb.compute_shortestpath_sparse(dataset, use_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_shortestpath.npz\"),\n",
        "                vectors_shortestpath, compressed=True)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start processing data set  ENZYMES\n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Extracting /content/tudataset/tud_benchmark/datasets/ENZYMES/ENZYMES/ENZYMES.zip\n",
            "Processing...\n",
            "Done!\n",
            "Start computing Weisfeihler-Lehman gram matrix and vector representations\n",
            "Start iteration  1\n",
            "Start iteration  2\n",
            "Start iteration  3\n",
            "Start iteration  4\n",
            "Start iteration  5\n",
            "Start computing Graphlet gram matrix\n",
            "Start computing Graphlet vector representation\n",
            "Start computing Shortest path gram matrix\n",
            "Start computing Shortest path vector representation\n",
            "Start processing data set  ENZYMES\n",
            "Start computing Weisfeihler-Lehman gram matrix and vector representations\n",
            "Start iteration  1\n",
            "Start iteration  2\n",
            "Start iteration  3\n",
            "Start iteration  4\n",
            "Start iteration  5\n",
            "Start computing Graphlet gram matrix\n",
            "Start computing Graphlet vector representation\n",
            "Start computing Shortest path gram matrix\n",
            "Start computing Shortest path vector representation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QCfal8eONNe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_wl1.csv', sep=';', header=None)\n",
        "df2 = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_wl2.csv', sep=';', header=None)\n",
        "df3 = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_wl3.csv', sep=';', header=None)\n",
        "df4 = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_wl4.csv', sep=';', header=None)\n",
        "df5 = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_wl5.csv', sep=';', header=None)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z7c_D4yQuMX"
      },
      "source": [
        "from auxiliarymethods import auxiliary_methods as aux\n",
        "from auxiliarymethods import kernel_evaluation as ke\n",
        "\n",
        "dfs = [df1, df2, df3, df3, df4, df5]\n",
        "classes = dp.get_dataset('ENZYMES')\n",
        "all_matrices = []\n",
        "for df in dfs:\n",
        "  df_np = df.to_numpy()\n",
        "  gm = aux.normalize_gram_matrix(df_np)\n",
        "  all_matrices.append(gm)\n",
        "\n",
        "accuracy, std_10, std_100 = ke.kernel_svm_evaluation(all_matrices, classes, num_repetitions=10, all_std=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlO05E6lSnpY"
      },
      "source": [
        "sp = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_shortestpath.csv', sep=';', header=None).to_numpy()\n",
        "graphlet = pd.read_csv('/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_gram_matrix_graphlet.csv', sep=';', header=None).to_numpy()\n",
        "\n",
        "baseline_kernels = {\n",
        "    'WL': dfs,\n",
        "    'SP': [sp],\n",
        "    'GRAPHLET': [graphlet]\n",
        "}\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss61LI-cTQ6e"
      },
      "source": [
        "accuracy_sp, std_10_sp, std_100_sp = ke.kernel_svm_evaluation(baseline_kernels['SP'], classes, num_repetitions=10, all_std=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqQWGjUmTVWB",
        "outputId": "d2711920-b147-4f2b-b1f4-bc48c0f9c454"
      },
      "source": [
        "accuracy_gl, std_10_gl, std_100_gl = ke.kernel_svm_evaluation(baseline_kernels['GRAPHLET'], classes, num_repetitions=10, all_std=True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 73924.,  30546.,  35514., ...,  79166., 117398.,  96672.],\n",
              "       [ 30546.,  15744.,  16882., ...,  36894.,  56388.,  46384.],\n",
              "       [ 35514.,  16882.,  21316., ...,  33136.,  54940.,  44536.],\n",
              "       ...,\n",
              "       [ 79166.,  36894.,  33136., ..., 316796., 227164., 199264.],\n",
              "       [117398.,  56388.,  54940., ..., 227164., 337252., 289668.],\n",
              "       [ 96672.,  46384.,  44536., ..., 199264., 289668., 256200.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkt9ZBeKTzlB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lpO07rCTVx8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}