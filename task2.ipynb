{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of generate_kernels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markkod/pc3-enzymes/blob/exploratory_da/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VxEwG3kUGD08",
        "outputId": "ca968cf1-f3f9-41ea-e0f8-8b2bdac252bb"
      },
      "source": [
        "#preinstalled version of pytorch has to be the same as the pre-compiled versions of the pytorch-geometric packages that we download later on.\r\n",
        "#versions might change quickly, so if you get a strange error later on, check the torch version of Google colab later on as follows:\r\n",
        "\r\n",
        "import torch\r\n",
        "torch.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxkdv434hIXP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-VN1RcQBUvc",
        "outputId": "295fc11e-5a77-4212-ee94-b526155c17ef"
      },
      "source": [
        "# Script to generate variations of the kernels yourself\n",
        "# https://ucloud.univie.ac.at/index.php/s/E3YKph0jkpbw8TN\n",
        "\n",
        "\n",
        "# #Download the TUDataset Repository with\n",
        "!git clone https://github.com/chrsmrrs/tudataset.git\n",
        "# #move this script to tudataset/tud_benchmark\n",
        "\n",
        "# #Install pytorch geometric: https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "# #Here is the gpu cuda installation, for the cpu version replace cu102 with cpu\n",
        "%pip --no-cache-dir install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-geometric\n",
        "\n",
        "%pip --no-cache-dir install pybind11\n",
        "!sudo apt-get install libeigen3-dev\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tudataset'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (366/366), done.\u001b[K\n",
            "remote: Total 3344 (delta 244), reused 300 (delta 114), pack-reused 2859\u001b[K\n",
            "Receiving objects: 100% (3344/3344), 8.47 MiB | 22.59 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 10.9MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 87.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 11.7MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (1.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (51.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp36-none-any.whl size=322720 sha256=9f42bcb7d1b955bd998d09f5b48d9e2ff0cca09aec98894ca31e11d8df8ae62f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vducu7it/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n",
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/84/fc9dc13ee536ba5e6b8fd10ce368fea5b738fe394c3b296cde7c9b144a92/pybind11-2.6.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 9.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.6.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (645 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 145480 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXKQ-3OcCzMK",
        "outputId": "79d3f47f-f9d0-46c2-cf6f-4cb11dae4aec"
      },
      "source": [
        "%cd ..\n",
        "%cd /content/tudataset/tud_benchmark/kernel_baselines/\n",
        "! ls\n",
        "! g++ -I /usr/include/eigen3 -O3 -shared -std=c++11 -fPIC `python3 -m pybind11 --includes`  kernel_baselines.cpp src/*cpp -o ../kernel_baselines`python3-config --extension-suffix`\n",
        "%cd .."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tudataset\n",
            "/content/tudataset/tud_benchmark/kernel_baselines\n",
            "kernel_baselines.cpp  src\n",
            "/content/tudataset/tud_benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjESzy3qMo8C",
        "outputId": "3e29e9a1-1631-4fac-c992-532450ad5837"
      },
      "source": [
        "!ls -al /usr/local/cuda"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lrwxrwxrwx 1 root root 9 Dec 21 17:24 /usr/local/cuda -> cuda-10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HOSZDPBbNV"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import kernel_baselines as kb\n",
        "import auxiliarymethods\n",
        "from auxiliarymethods import datasets as dp\n",
        "from scipy.sparse import save_npz\n",
        "from scipy.sparse import load_npz\n",
        "from auxiliarymethods import auxiliary_methods as aux\n",
        "from auxiliarymethods import kernel_evaluation as ke"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pq17mvdBdym"
      },
      "source": [
        "def setup_directory(dir_name, verbose=False):\n",
        "    \"\"\"\n",
        "    Setup directory in case it does not exist\n",
        "    Parameters:\n",
        "    -------------\n",
        "    dir_name: str, path + name to directory\n",
        "    verbose: bool, indicates whether directory creation should be printed or not.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        try:\n",
        "            os.makedirs(dir_name)\n",
        "            if verbose:\n",
        "                print(\"Created Directory: {}\".format(dir_name))\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\n",
        "                \"Could not create directory: {}\\n {}\".format(dir_name, e))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWVqxq5B8RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49a6b03-7eab-4035-f764-cc6e69bde416"
      },
      "source": [
        "use_edge_labels = False\n",
        "for USE_LABELS in [True, False]:# Except IMDB-BINARY\n",
        "    for dataset, use_labels in [[\"ENZYMES\", USE_LABELS]]:\n",
        "        if use_labels:\n",
        "            base_path = os.path.join(\"kernels\",\"node_labels\")\n",
        "        else:\n",
        "            base_path = os.path.join(\"kernels\",\"without_labels\")\n",
        "        setup_directory(base_path)\n",
        "        print(\"Start processing data set \", dataset)\n",
        "        # Download dataset.\n",
        "        classes = dp.get_dataset(dataset)\n",
        "        # *Weisfeihler-Lehman*\n",
        "        print(\"Start computing Weisfeihler-Lehman gram matrix and vector representations\")\n",
        "        iterations = 6\n",
        "        #0 taking just the nodelabels themselves into account; \n",
        "        #1 considers nearest-neighbours, 2 one layer deeper and so on\n",
        "        for i in range(1, iterations):\n",
        "            print(\"Start iteration \", i)\n",
        "            #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
        "            gram_matrix_wl = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\n",
        "            np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{i}.csv\"),\n",
        "                    gram_matrix_wl,\n",
        "                    delimiter=\";\")\n",
        "            #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\n",
        "            vectors_wl = kb.compute_wl_1_sparse(dataset, i, use_labels, use_edge_labels)\n",
        "            save_npz(os.path.join(base_path,f\"{dataset}_vectors_wl{i}.npz\"),\n",
        "                    vectors_wl, compressed=True)\n",
        "\n",
        "        # *Graphlet kernel*\n",
        "        print(\"Start computing Graphlet gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Graphlet kernel\n",
        "        gram_matrix_graphlet= kb.compute_graphlet_dense(dataset, use_labels, use_edge_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_graphlet.csv\"),\n",
        "                gram_matrix_graphlet,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Graphlet vector representation\")\n",
        "        #Sparse Vectors for the Graphlet kernel\n",
        "        vectors_graphlet = kb.compute_graphlet_sparse(dataset, use_labels, use_edge_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_graphlet.npz\"),\n",
        "                vectors_graphlet, compressed=True)\n",
        "\n",
        "\n",
        "        print(\"Start computing Shortest path gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Shortest path kernel\n",
        "        gram_matrix_shortestpath = kb.compute_shortestpath_dense(dataset, use_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_shortestpath.csv\"),\n",
        "                gram_matrix_shortestpath,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Shortest path vector representation\")\n",
        "\n",
        "        #Sparse Vectors for the Shortest path kernel\n",
        "        vectors_shortestpath = kb.compute_shortestpath_sparse(dataset, use_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_shortestpath.npz\"),\n",
        "                vectors_shortestpath, compressed=True)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start processing data set  ENZYMES\n",
            "Start computing Weisfeihler-Lehman gram matrix and vector representations\n",
            "Start iteration  1\n",
            "Start iteration  2\n",
            "Start iteration  3\n",
            "Start iteration  4\n",
            "Start iteration  5\n",
            "Start computing Graphlet gram matrix\n",
            "Start computing Graphlet vector representation\n",
            "Start computing Shortest path gram matrix\n",
            "Start computing Shortest path vector representation\n",
            "Start processing data set  ENZYMES\n",
            "Start computing Weisfeihler-Lehman gram matrix and vector representations\n",
            "Start iteration  1\n",
            "Start iteration  2\n",
            "Start iteration  3\n",
            "Start iteration  4\n",
            "Start iteration  5\n",
            "Start computing Graphlet gram matrix\n",
            "Start computing Graphlet vector representation\n",
            "Start computing Shortest path gram matrix\n",
            "Start computing Shortest path vector representation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkt9ZBeKTzlB"
      },
      "source": [
        "def find_keys_with_condition(data, cond):\n",
        "    return list(filter(lambda x: cond in x, data.keys()))\n",
        "\n",
        "def load_data():\n",
        "  result = {}\n",
        "  extensions = ['csv', 'npz']\n",
        "  types = ['gram_matrix', 'vectors']\n",
        "  algos = ['wl1', 'wl2', 'wl3', 'wl4', 'wl5', 'shortestpath', 'graphlet']\n",
        "  base_name = '/content/tudataset/tud_benchmark/kernels/node_labels/ENZYMES_{0}_{1}.{2}'\n",
        "\n",
        "  for t, e in zip(types, extensions):\n",
        "    result[t] = {}\n",
        "    for a in algos:\n",
        "      algo_name = 'wl' if 'wl' in a else a\n",
        "\n",
        "      if algo_name not in result[t].keys():\n",
        "        result[t][algo_name] = []\n",
        "\n",
        "      file_name = base_name.format(t, a, e)\n",
        "\n",
        "      if e == 'csv':\n",
        "        f = np.loadtxt(file_name, delimiter=';')\n",
        "      else:\n",
        "        f = load_npz(file_name)\n",
        "      \n",
        "      result[t][algo_name].append(f)\n",
        "  return result"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lpO07rCTVx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96777695-bd73-4cec-9a6f-c6078533b4c3"
      },
      "source": [
        "data = load_data()\n",
        "data"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gram_matrix': {'graphlet': [array([[11177.,  6596.,  4333., ..., 11081., 13908., 10164.],\n",
              "          [ 6596.,  4879.,  3005., ...,  4882.,  5786.,  3278.],\n",
              "          [ 4333.,  3005.,  2132., ...,  2814.,  3236.,  1674.],\n",
              "          ...,\n",
              "          [11081.,  4882.,  2814., ..., 20397., 22060., 18291.],\n",
              "          [13908.,  5786.,  3236., ..., 22060., 28850., 24883.],\n",
              "          [10164.,  3278.,  1674., ..., 18291., 24883., 22359.]])],\n",
              "  'shortestpath': [array([[ 73924.,  30546.,  35514., ...,  79166., 117398.,  96672.],\n",
              "          [ 30546.,  15744.,  16882., ...,  36894.,  56388.,  46384.],\n",
              "          [ 35514.,  16882.,  21316., ...,  33136.,  54940.,  44536.],\n",
              "          ...,\n",
              "          [ 79166.,  36894.,  33136., ..., 316796., 227164., 199264.],\n",
              "          [117398.,  56388.,  54940., ..., 227164., 337252., 289668.],\n",
              "          [ 96672.,  46384.,  44536., ..., 199264., 289668., 256200.]])],\n",
              "  'wl': [array([[ 874.,  502.,  585., ...,  973.,  998.,  935.],\n",
              "          [ 502.,  360.,  362., ...,  591.,  615.,  580.],\n",
              "          [ 585.,  362.,  476., ...,  587.,  678.,  636.],\n",
              "          ...,\n",
              "          [ 973.,  591.,  587., ..., 1930., 1417., 1351.],\n",
              "          [ 998.,  615.,  678., ..., 1417., 1488., 1431.],\n",
              "          [ 935.,  580.,  636., ..., 1351., 1431., 1432.]]),\n",
              "   array([[ 919.,  502.,  585., ...,  973.,  998.,  959.],\n",
              "          [ 502.,  385.,  362., ...,  591.,  615.,  595.],\n",
              "          [ 585.,  362.,  511., ...,  587.,  678.,  655.],\n",
              "          ...,\n",
              "          [ 973.,  591.,  587., ..., 1999., 1417., 1369.],\n",
              "          [ 998.,  615.,  678., ..., 1417., 1545., 1475.],\n",
              "          [ 959.,  595.,  655., ..., 1369., 1475., 1546.]]),\n",
              "   array([[ 964.,  502.,  585., ...,  973.,  998.,  983.],\n",
              "          [ 502.,  408.,  362., ...,  591.,  615.,  610.],\n",
              "          [ 585.,  362.,  546., ...,  587.,  678.,  674.],\n",
              "          ...,\n",
              "          [ 973.,  591.,  587., ..., 2054., 1417., 1387.],\n",
              "          [ 998.,  615.,  678., ..., 1417., 1596., 1501.],\n",
              "          [ 983.,  610.,  674., ..., 1387., 1501., 1652.]]),\n",
              "   array([[1009.,  502.,  585., ...,  973.,  998., 1007.],\n",
              "          [ 502.,  431.,  362., ...,  591.,  615.,  625.],\n",
              "          [ 585.,  362.,  581., ...,  587.,  678.,  693.],\n",
              "          ...,\n",
              "          [ 973.,  591.,  587., ..., 2109., 1417., 1405.],\n",
              "          [ 998.,  615.,  678., ..., 1417., 1647., 1527.],\n",
              "          [1007.,  625.,  693., ..., 1405., 1527., 1758.]]),\n",
              "   array([[1054.,  502.,  585., ...,  973.,  998., 1031.],\n",
              "          [ 502.,  454.,  362., ...,  591.,  615.,  640.],\n",
              "          [ 585.,  362.,  616., ...,  587.,  678.,  712.],\n",
              "          ...,\n",
              "          [ 973.,  591.,  587., ..., 2164., 1417., 1423.],\n",
              "          [ 998.,  615.,  678., ..., 1417., 1698., 1553.],\n",
              "          [1031.,  640.,  712., ..., 1423., 1553., 1864.]])]},\n",
              " 'vectors': {'graphlet': [<600x3455 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 3455 stored elements in Compressed Sparse Column format>],\n",
              "  'shortestpath': [<600x25460 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 25460 stored elements in Compressed Sparse Column format>],\n",
              "  'wl': [<600x9658 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 9658 stored elements in Compressed Sparse Column format>,\n",
              "   <600x25577 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 25577 stored elements in Compressed Sparse Column format>,\n",
              "   <600x42457 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 42457 stored elements in Compressed Sparse Column format>,\n",
              "   <600x59599 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 59599 stored elements in Compressed Sparse Column format>,\n",
              "   <600x76881 sparse matrix of type '<class 'numpy.float64'>'\n",
              "   \twith 76881 stored elements in Compressed Sparse Column format>]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnky-P2CZc5o"
      },
      "source": [
        "def eval_kernel(kernel, classes, mode, n_reps=10, all_std=True):\n",
        "  normalized = []\n",
        "  print(f'Starting normalization of {len(kernel)} elements...')\n",
        "  for array in kernel:\n",
        "    if mode == 'LINEAR':\n",
        "      normalized.append(aux.normalize_feature_vector(array))\n",
        "    else:\n",
        "      normalized.append(aux.normalize_gram_matrix(array))\n",
        "  print(f'Normalization finished, starting {mode} SVM...')\n",
        "  if mode == 'LINEAR':\n",
        "    return ke.linear_svm_evaluation(normalized, classes, num_repetitions=n_reps, all_std=all_std)\n",
        "  return ke.kernel_svm_evaluation(normalized, classes, num_repetitions=n_reps, all_std=all_std)\n",
        "\n",
        "def eval_all(data):\n",
        "  classes = dp.get_dataset('ENZYMES')\n",
        "  result = {}\n",
        "  for data_type in data.keys():\n",
        "    mode = 'LINEAR' if data_type == 'vectors' else 'KERNEL'\n",
        "    result[data_type] = {}\n",
        "    print('MODE:', mode)\n",
        "    for kernel in data[data_type]:\n",
        "      print(f'Evaluating {kernel} SVM...')\n",
        "      result[data_type][kernel] = eval_kernel(data[data_type][kernel], classes, mode)\n",
        "      print(f'{data_type}-{kernel} : {result[data_type][kernel]}')\n",
        "  return result\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCwcC_PXnIwA",
        "outputId": "979cdbc6-86ed-42d1-827e-96df07ec1698"
      },
      "source": [
        "eval_all(data)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODE: KERNEL\n",
            "Evaluating wl SVM...\n",
            "Starting normalization of 5 elements...\n",
            "Normalization finished, starting KERNEL SVM...\n",
            "gram_matrix-wl : (50.33333333333333, 1.1279282877125771, 6.411794687223782)\n",
            "Evaluating shortestpath SVM...\n",
            "Starting normalization of 1 elements...\n",
            "Normalization finished, starting KERNEL SVM...\n",
            "gram_matrix-shortestpath : (41.15, 1.131493604832911, 6.1540185606191065)\n",
            "Evaluating graphlet SVM...\n",
            "Starting normalization of 1 elements...\n",
            "Normalization finished, starting KERNEL SVM...\n",
            "gram_matrix-graphlet : (30.56666666666667, 0.727247474309049, 5.422279143599222)\n",
            "MODE: LINEAR\n",
            "Evaluating wl SVM...\n",
            "Starting normalization of 5 elements...\n",
            "Normalization finished, starting LINEAR SVM...\n",
            "vectors-wl : (51.36666666666666, 1.2106013198223256, 6.567512635863157)\n",
            "Evaluating shortestpath SVM...\n",
            "Starting normalization of 1 elements...\n",
            "Normalization finished, starting LINEAR SVM...\n",
            "vectors-shortestpath : (40.06666666666667, 1.2498888839501803, 6.337367136455188)\n",
            "Evaluating graphlet SVM...\n",
            "Starting normalization of 1 elements...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py:585: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return self.astype(np.float_)._mul_scalar(1./other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Normalization finished, starting LINEAR SVM...\n",
            "vectors-graphlet : (30.85, 0.8214147686901061, 5.619880386232038)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gram_matrix': {'graphlet': (30.56666666666667,\n",
              "   0.727247474309049,\n",
              "   5.422279143599222),\n",
              "  'shortestpath': (41.15, 1.131493604832911, 6.1540185606191065),\n",
              "  'wl': (50.33333333333333, 1.1279282877125771, 6.411794687223782)},\n",
              " 'vectors': {'graphlet': (30.85, 0.8214147686901061, 5.619880386232038),\n",
              "  'shortestpath': (40.06666666666667, 1.2498888839501803, 6.337367136455188),\n",
              "  'wl': (51.36666666666666, 1.2106013198223256, 6.567512635863157)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}